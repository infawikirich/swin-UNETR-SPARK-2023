None

        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-5)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)



        max_epoch =  12
        validation = 4

    
MONAI version: 1.2.0rc7+9.g84940298
Numpy version: 1.24.2
Pytorch version: 1.13.1
MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False
MONAI rev id: 84940298bff9ff1f54845eb8ae7422c0092c09c1
MONAI __file__: /home/guest185/hackathon_38/lib/python3.8/site-packages/monai/__init__.py

Optional dependencies:
Pytorch Ignite version: 0.4.2
ITK version: NOT INSTALLED or UNKNOWN VERSION.
Nibabel version: 5.1.0
scikit-image version: 0.19.3
Pillow version: 9.5.0
Tensorboard version: 2.13.0
gdown version: 4.7.1
TorchVision version: 0.14.1
tqdm version: 4.65.0
lmdb version: 1.2.1
psutil version: 5.9.4
pandas version: 1.5.3
einops version: 0.6.1
transformers version: 4.21.3
mlflow version: NOT INSTALLED or UNKNOWN VERSION.
pynrrd version: 1.0.0

For details about installing the optional dependencies, please visit:
    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies

/tmp/tmpg7kg9rh6
image shape: (240, 240, 155), label shape: (240, 240, 155)
Sun Aug 13 09:44:22 2023 Epoch: 0
In the future `np.bool` will be defined as the corresponding NumPy scalar.
In the future `np.bool` will be defined as the corresponding NumPy scalar.
In the future `np.bool` will be defined as the corresponding NumPy scalar.
In the future `np.bool` will be defined as the corresponding NumPy scalar.
monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.
In the future `np.bool` will be defined as the corresponding NumPy scalar.
In the future `np.bool` will be defined as the corresponding NumPy scalar.
Epoch 0/12 0/48 loss: 0.8364 time 29.54s
Epoch 0/12 1/48 loss: 0.8989 time 4.30s
Epoch 0/12 2/48 loss: 0.8927 time 4.62s
Epoch 0/12 3/48 loss: 0.8862 time 4.23s
Epoch 0/12 4/48 loss: 0.8900 time 4.25s
Epoch 0/12 5/48 loss: 0.9051 time 4.26s
Epoch 0/12 6/48 loss: 0.9121 time 4.26s
Epoch 0/12 7/48 loss: 0.9101 time 4.27s
Epoch 0/12 8/48 loss: 0.9091 time 4.29s
Epoch 0/12 9/48 loss: 0.9147 time 4.29s
Epoch 0/12 10/48 loss: 0.9085 time 4.31s
Epoch 0/12 11/48 loss: 0.9061 time 4.33s
Epoch 0/12 12/48 loss: 0.9076 time 4.36s
Epoch 0/12 13/48 loss: 0.9078 time 4.36s
Epoch 0/12 14/48 loss: 0.9095 time 4.37s
Epoch 0/12 15/48 loss: 0.9143 time 4.38s
Epoch 0/12 16/48 loss: 0.9171 time 4.40s
Epoch 0/12 17/48 loss: 0.9216 time 4.41s
Epoch 0/12 18/48 loss: 0.9186 time 4.42s
Epoch 0/12 19/48 loss: 0.9174 time 4.43s
Epoch 0/12 20/48 loss: 0.9177 time 4.44s
Epoch 0/12 21/48 loss: 0.9177 time 4.43s
Epoch 0/12 22/48 loss: 0.9187 time 4.41s
Epoch 0/12 23/48 loss: 0.9209 time 4.43s
Epoch 0/12 24/48 loss: 0.9225 time 4.43s
Epoch 0/12 25/48 loss: 0.9235 time 4.43s
Epoch 0/12 26/48 loss: 0.9215 time 4.44s
Epoch 0/12 27/48 loss: 0.9214 time 4.45s
Epoch 0/12 28/48 loss: 0.9180 time 4.44s
Epoch 0/12 29/48 loss: 0.9163 time 4.45s
Epoch 0/12 30/48 loss: 0.9148 time 4.44s
Epoch 0/12 31/48 loss: 0.9140 time 4.45s
Epoch 0/12 32/48 loss: 0.9102 time 4.46s
Epoch 0/12 33/48 loss: 0.9086 time 4.46s
Epoch 0/12 34/48 loss: 0.9067 time 4.45s
Epoch 0/12 35/48 loss: 0.9056 time 4.45s
Epoch 0/12 36/48 loss: 0.9063 time 4.44s
Epoch 0/12 37/48 loss: 0.9069 time 4.43s
Epoch 0/12 38/48 loss: 0.9078 time 4.43s
Epoch 0/12 39/48 loss: 0.9061 time 4.44s
Epoch 0/12 40/48 loss: 0.9078 time 4.42s
Epoch 0/12 41/48 loss: 0.9088 time 4.43s
Epoch 0/12 42/48 loss: 0.9105 time 4.43s
Epoch 0/12 43/48 loss: 0.9074 time 4.43s
Epoch 0/12 44/48 loss: 0.9059 time 4.43s
Epoch 0/12 45/48 loss: 0.9072 time 4.42s
Epoch 0/12 46/48 loss: 0.9078 time 4.41s
Epoch 0/12 47/48 loss: 0.9064 time 4.42s
Final training  0/11 loss: 0.9064 time 236.37s
None of the inputs have requires_grad=True. Gradients will be None
Val 0/12 0/12 , dice_tc: 0.10628222 , dice_wt: 0.276116 , dice_et: 0.16349435 , time 49.74s
Traceback (most recent call last):
  File "ssa_swin_model.py", line 424, in <module>
    ) = trainer(
  File "ssa_swin_model.py", line 362, in trainer
    val_acc = val_epoch(
  File "ssa_swin_model.py", line 315, in val_epoch
    generate_segmentation_nifti(val_output, case_id, timepoint, output_dir)
  File "/home/guest185/SPARK_Stater/Africa_SSA_Model/segmentation_generate.py", line 24, in generate_segmentation_nifti
    output_filename = f"BraTS-GLI-seg-{case_id}-{timepoint.zfill(3)}.nii.gz"
AttributeError: 'tuple' object has no attribute 'zfill'
